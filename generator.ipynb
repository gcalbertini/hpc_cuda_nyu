{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "destination = \"../generated_data\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given functions\n",
    "def get_d(deg_true):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    deg_true: (int) degree of the polynomial g\n",
    "\n",
    "    Returns:\n",
    "    a: (np array of size (deg_true + 1)) coefficients of polynomial g\n",
    "    \"\"\"\n",
    "    return 5 * np.random.randn(deg_true + 1)\n",
    "\n",
    "\n",
    "def get_design_mat(x, deg):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x: (np.array of size N)\n",
    "    deg: (int) max degree used to generate the design matrix\n",
    "\n",
    "    Returns:\n",
    "    X: (np.array of size N x (deg_true + 1)) design matrix\n",
    "    \"\"\"\n",
    "    X = np.array([x ** i for i in range(deg + 1)]).T\n",
    "    return X\n",
    "\n",
    "\n",
    "def draw_sample(deg_true, a, N):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    deg_true: (int) degree of the polynomial g\n",
    "    a: (np.array of size deg_true) parameter of g\n",
    "    N: (int) size of sample to draw\n",
    "\n",
    "    Returns:\n",
    "    x: (np.array of size N)\n",
    "    y: (np.array of size N)\n",
    "    \"\"\"\n",
    "    x = np.sort(np.random.rand(N))\n",
    "    X = get_design_mat(x, deg_true)\n",
    "    y = X @ a\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def draw_sample_with_noise(deg_true, a, N):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    deg_true: (int) degree of the polynomial g\n",
    "    a: (np.array of size deg_true) parameter of g\n",
    "    N: (int) size of sample to draw\n",
    "\n",
    "    Returns:\n",
    "    x: (np.array of size N)\n",
    "    y: (np.array of size N)\n",
    "    \"\"\"\n",
    "    x = np.random.rand(N)\n",
    "    X = get_design_mat(x, deg_true)\n",
    "    y = X @ a + np.random.randn(N)\n",
    "    return x, y\n",
    "\n",
    "# Define our least squares estimator function\n",
    "\n",
    "\n",
    "def least_squares_estimator(X, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X: (np.matrix of size N x (deg_true +1))\n",
    "    y: (np.array) of size deg_true + 1 x 1\n",
    "\n",
    "    Returns:\n",
    "    b_hat: (np.array) of size N x (deg_true + 1)\n",
    "    \"\"\"\n",
    "    # Make sure N > d\n",
    "    if X.shape[0] < X.shape[1]:\n",
    "        raise ValueError(\"You must have at least as many rows as columns!\")\n",
    "    else:\n",
    "        # Compute the solution for b using the closed form linear algebra solution\n",
    "        b_hat = np.linalg.inv(X.T@X) @ X.T @ y\n",
    "        return b_hat\n",
    "\n",
    "\n",
    "def empirical_risk(X, y, b_hat):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X: (np.matrix of size N x (deg_true +1))\n",
    "    y: (np.array) of size deg_true + 1 x 1\n",
    "    b_hat: (np.array) of size N x (deg_true + 1)\n",
    "    Returns:\n",
    "    emp_risk: (float) \n",
    "    \"\"\"\n",
    "    # Get # of observations\n",
    "    N = X.shape[0]\n",
    "    # Calculate Predictions\n",
    "    y_hat = X @ b_hat\n",
    "    # Calculate squared errors and then empirical risk\n",
    "    sum_of_squared_errors = sum((y_hat-y)**2)\n",
    "    emp_risk = sum_of_squared_errors / N\n",
    "    emp_risk = emp_risk / 2  # because we have 1/2 in our loss function\n",
    "    return emp_risk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef generate(x, d):\\n    return np.array([x**i for i in range(d+1)])\\n\\n\\n# Generate a helper variable\\nn = list(range(N))\\nx = np.linspace(0, 1, N)\\n\\n# Ok the following requires that you have enough data pts so can just comment out as appropriate (N>=20)\\n# Calculate e_g, e_t for various N\\'s of polynomial degree 2\\ntrain_error_arr_2, test_error_arr_2, b_hat_2_1000 = poly_risk_gen(\\n    2, n, X_train_noise, y_train_noise, X_test_noise, y_test_noise)\\n\\n# Calculate e_g, e_t for various N\\'s of polynomial degree 5\\ntrain_error_arr_5, test_error_arr_5, b_hat_5_1000 = poly_risk_gen(\\n    5, n, X_train_noise, y_train_noise, X_test_noise, y_test_noise)\\n\\n# Calculate e_g, e_t for various N\\'s of polynomial degree 10\\ntrain_error_arr_10, test_error_arr_10, b_hat_10_1000 = poly_risk_gen(\\n    10, n, X_train_noise, y_train_noise, X_test_noise, y_test_noise)\\nfunc_g = coef @ generate(x, d)\\nfunc_b_hat_2 = b_hat_2_1000 @ generate(x, 2)\\nfunc_b_hat_5 = b_hat_5_1000 @ generate(x, 5)\\nfunc_b_hat_10 = b_hat_10_1000 @ generate(x, 10)\\n\\n# B_hat predictions given N data points\\nplt.figure(figsize=(15, 8))\\nplt.scatter(X_train_noise[:N], y_train_noise[:N])\\nplt.plot(x, func_g)\\nplt.plot(x, func_b_hat_2)\\nplt.plot(x, func_b_hat_5)\\nplt.plot(x, func_b_hat_10)\\n\\nplt.legend(labels=[r\\'$f_{g(x)}$\\', r\\'$f_{\\\\hat{b}(x; d=2)}$\\',\\n           r\\'$f_{\\\\hat{b}(x; d=5)}$\\', r\\'$f_{\\\\hat{b}(x; d=10)}$\\', \\'Training Data\\'])\\nplt.title(\\n    \"Polynomial Estimation Functions vs Ground Truth and Training Data, N={n}\".format(n=N))\\nplt.savefig(\\'generated_data//loss_over_N\\')\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 10\n",
    "N = 200\n",
    "alpha = 0.05\n",
    "coef = get_d(d)\n",
    "\n",
    "print(d)\n",
    "print(N)\n",
    "os.makedirs('generated_data', exist_ok=True)\n",
    "X_train_noise, y_train_noise = draw_sample_with_noise(d, coef, N)\n",
    "X_test_noise, y_test_noise = draw_sample_with_noise(d, coef, N)\n",
    "Xd_train = get_design_mat(X_train_noise, d).reshape([N, d+1])\n",
    "Xd_test = get_design_mat(X_test_noise, d).reshape([N, d+1])\n",
    "Xd_train = Xd_train[:,1:] #they drop bias column\n",
    "Xd_test = Xd_test[:,1:]\n",
    "\n",
    "np.savetxt('generated_data//df_X_train.csv', Xd_train, delimiter=',')\n",
    "np.savetxt('generated_data//df_y_train.csv',\n",
    "           y_train_noise, delimiter=',')\n",
    "np.savetxt('generated_data//df_X_test.csv', Xd_test, delimiter=',')\n",
    "np.savetxt('generated_data//df_y_test.csv',\n",
    "           y_test_noise, delimiter=',')\n",
    "np.savetxt('generated_data//df_weights.csv',\n",
    "           coef.reshape([1, d+1]), delimiter=',')\n",
    "\n",
    "'''\n",
    "def generate(x, d):\n",
    "    return np.array([x**i for i in range(d+1)])\n",
    "\n",
    "\n",
    "# Generate a helper variable\n",
    "n = list(range(N))\n",
    "x = np.linspace(0, 1, N)\n",
    "\n",
    "# Ok the following requires that you have enough data pts so can just comment out as appropriate (N>=20)\n",
    "# Calculate e_g, e_t for various N's of polynomial degree 2\n",
    "train_error_arr_2, test_error_arr_2, b_hat_2_1000 = poly_risk_gen(\n",
    "    2, n, X_train_noise, y_train_noise, X_test_noise, y_test_noise)\n",
    "\n",
    "# Calculate e_g, e_t for various N's of polynomial degree 5\n",
    "train_error_arr_5, test_error_arr_5, b_hat_5_1000 = poly_risk_gen(\n",
    "    5, n, X_train_noise, y_train_noise, X_test_noise, y_test_noise)\n",
    "\n",
    "# Calculate e_g, e_t for various N's of polynomial degree 10\n",
    "train_error_arr_10, test_error_arr_10, b_hat_10_1000 = poly_risk_gen(\n",
    "    10, n, X_train_noise, y_train_noise, X_test_noise, y_test_noise)\n",
    "func_g = coef @ generate(x, d)\n",
    "func_b_hat_2 = b_hat_2_1000 @ generate(x, 2)\n",
    "func_b_hat_5 = b_hat_5_1000 @ generate(x, 5)\n",
    "func_b_hat_10 = b_hat_10_1000 @ generate(x, 10)\n",
    "\n",
    "# B_hat predictions given N data points\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(X_train_noise[:N], y_train_noise[:N])\n",
    "plt.plot(x, func_g)\n",
    "plt.plot(x, func_b_hat_2)\n",
    "plt.plot(x, func_b_hat_5)\n",
    "plt.plot(x, func_b_hat_10)\n",
    "\n",
    "plt.legend(labels=[r'$f_{g(x)}$', r'$f_{\\hat{b}(x; d=2)}$',\n",
    "           r'$f_{\\hat{b}(x; d=5)}$', r'$f_{\\hat{b}(x; d=10)}$', 'Training Data'])\n",
    "plt.title(\n",
    "    \"Polynomial Estimation Functions vs Ground Truth and Training Data, N={n}\".format(n=N))\n",
    "plt.savefig('generated_data//loss_over_N')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_square_loss(X, y, theta):\n",
    "    assert X.shape[1] == theta.shape[0], print(\"Dimensions don't match for X and theta - \", X.shape, theta.shape)\n",
    "    preds = X @ theta\n",
    "    m = len(y)\n",
    "    assert len(preds) == len(y), print(\"Dimensions don't match for preds and y - \", preds.shape, y.shape)\n",
    "    loss = (1.0/m) * ((preds-y).T @ (preds - y))  # * np.sum((preds - y)**2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_square_loss_gradient(X, y, theta):\n",
    "    assert X.shape[1] == theta.shape[0], print(\"Dimensions don't match for X and theta - \", X.shape, theta.shape)\n",
    "    preds = X @ theta\n",
    "    m = len(y)\n",
    "    grad = (2.0/m) * ((preds - y) @ X)\n",
    "    return grad\n",
    "\n",
    "\n",
    "def grad_checker(X, y, theta, epsilon=0.01, tolerance=1e-4):\n",
    "    fn_gradient = compute_square_loss_gradient(\n",
    "        X, y, theta)  # The true gradient\n",
    "    num_features = theta.shape[0]\n",
    "    # Initialize the gradient we approximate\n",
    "    approx_grad = np.zeros(num_features)\n",
    "    e = [np.zeros(num_features) for i in range(num_features)]\n",
    "    for i in range(num_features):\n",
    "        e[i][i] = 1\n",
    "    approx = []\n",
    "    for ei in e:\n",
    "        upper = compute_square_loss(X, y, theta + epsilon*ei)\n",
    "        lower = compute_square_loss(X, y, theta - epsilon*ei)\n",
    "        approx.append((upper - lower)/(2.0 * epsilon))\n",
    "\n",
    "    approx = np.asarray(approx)\n",
    "    if np.linalg.norm(fn_gradient - approx) > tolerance:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def batch_grad_descent(X, y, alpha=0.1, num_step=1000, grad_check=False):\n",
    "    num_instances, num_features = X.shape[0], X.shape[1]\n",
    "    theta_hist = np.zeros((num_step + 1, num_features))  # Initialize theta_hist\n",
    "    loss_hist = np.zeros(num_step + 1)  # Initialize loss_hist\n",
    "    theta = np.zeros(num_features)  # Initialize theta\n",
    "\n",
    "    for step in range(num_step):\n",
    "        theta_hist[step] = theta\n",
    "        loss_hist[step] = compute_square_loss(X, y, theta)\n",
    "        gradient = compute_square_loss_gradient(X, y, theta)\n",
    "\n",
    "        if grad_check:\n",
    "            if not grad_checker(X, y, theta):\n",
    "                sys.exit(\"ERROR: INCORRECT GRADIENT\")\n",
    "            else:\n",
    "                sys.stdout.write(\"GRAD CHECK PASSED\\n\")\n",
    "\n",
    "        theta -= alpha*gradient\n",
    "\n",
    "    # Off by one at end of arrays so recompute\n",
    "    theta_hist[step+1] = theta\n",
    "    loss_hist[step+1] = compute_square_loss(X, y, theta)\n",
    "\n",
    "    return theta_hist, loss_hist\n",
    "\n",
    "def compute_regularized_square_loss_gradient(X, y, theta, lambda_reg):\n",
    "\tassert X.shape[1] == theta.shape[0], print(\"Dimensions don't match for X and theta - \", X.shape, theta.shape)\n",
    "\tpreds = X @ theta\n",
    "\tm = len(y)\n",
    "\tgrad = ((2.0/m) * ((preds - y) @ X)) + (2 * lambda_reg * theta)\n",
    "\treturn grad\n",
    "\n",
    "def regularized_grad_descent(X, y, alpha=0.05, lambda_reg=10**-2, num_step=1000):\n",
    "\tnum_instances, num_features = X.shape[0], X.shape[1]\n",
    "\ttheta = np.zeros(num_features) #Initialize theta\n",
    "\ttheta_hist = np.zeros((num_step+1, num_features)) #Initialize theta_hist\n",
    "\tloss_hist = np.zeros(num_step+1) #Initialize loss_hist\n",
    "\n",
    "\tfor i in range(num_step+1):\n",
    "\t\ttheta_hist[i] = theta\n",
    "\t\tloss_hist[i] = compute_square_loss(X, y, theta)\n",
    "\t\tif i == num_step:\n",
    "\t\t\tbreak\n",
    "\t\tgrad = compute_regularized_square_loss_gradient(X, y, theta, lambda_reg)\n",
    "\t\ttheta = theta - alpha*grad\n",
    "\treturn loss_hist, theta_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n",
      "GRAD CHECK PASSED\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "theta_hist, loss_hist = batch_grad_descent(Xd_train, y_train_noise, alpha=alpha, num_step=500, grad_check=True)\n",
    "\n",
    "loss_test = []\n",
    "for t in range(len(theta_hist)):\n",
    "    loss_test.append(compute_square_loss(Xd_test, y_test_noise, theta_hist[t]))\n",
    "plt.plot(loss_test, label='test')\n",
    "plt.plot(loss_hist, label='train')\n",
    "plt.legend()\n",
    "plt.ylabel('Test and Train Square Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.savefig(\"generated_data/loss_batch_py.jpg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7f43726a79b79bb18500e3546bed249e1c1aa16f3227c093295a5c944512c00"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
