{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "destination = \"../generated_data\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given functions\n",
    "def get_d(deg_true):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    deg_true: (int) degree of the polynomial g\n",
    "\n",
    "    Returns:\n",
    "    a: (np array of size (deg_true + 1)) coefficients of polynomial g\n",
    "    \"\"\"\n",
    "    return 5 * np.random.randn(deg_true + 1)\n",
    "\n",
    "\n",
    "def get_design_mat(x, deg):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x: (np.array of size N)\n",
    "    deg: (int) max degree used to generate the design matrix\n",
    "\n",
    "    Returns:\n",
    "    X: (np.array of size N x (deg_true + 1)) design matrix\n",
    "    \"\"\"\n",
    "    X = np.array([x ** i for i in range(deg + 1)]).T\n",
    "    return X\n",
    "\n",
    "\n",
    "def draw_sample(deg_true, a, N):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    deg_true: (int) degree of the polynomial g\n",
    "    a: (np.array of size deg_true) parameter of g\n",
    "    N: (int) size of sample to draw\n",
    "\n",
    "    Returns:\n",
    "    x: (np.array of size N)\n",
    "    y: (np.array of size N)\n",
    "    \"\"\"\n",
    "    x = np.sort(np.random.rand(N))\n",
    "    X = get_design_mat(x, deg_true)\n",
    "    y = X @ a\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def draw_sample_with_noise(deg_true, a, N):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    deg_true: (int) degree of the polynomial g\n",
    "    a: (np.array of size deg_true) parameter of g\n",
    "    N: (int) size of sample to draw\n",
    "\n",
    "    Returns:\n",
    "    x: (np.array of size N)\n",
    "    y: (np.array of size N)\n",
    "    \"\"\"\n",
    "    x = np.random.rand(N)\n",
    "    X = get_design_mat(x, deg_true)\n",
    "    y = X @ a + np.random.randn(N)\n",
    "    return x, y\n",
    "\n",
    "# Define our least squares estimator function\n",
    "\n",
    "\n",
    "def least_squares_estimator(X, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X: (np.matrix of size N x (deg_true +1))\n",
    "    y: (np.array) of size deg_true + 1 x 1\n",
    "\n",
    "    Returns:\n",
    "    b_hat: (np.array) of size N x (deg_true + 1)\n",
    "    \"\"\"\n",
    "    # Make sure N > d\n",
    "    if X.shape[0] < X.shape[1]:\n",
    "        raise ValueError(\"You must have at least as many rows as columns!\")\n",
    "    else:\n",
    "        # Compute the solution for b using the closed form linear algebra solution\n",
    "        b_hat = np.linalg.inv(X.T@X) @ X.T @ y\n",
    "        return b_hat\n",
    "\n",
    "\n",
    "def empirical_risk(X, y, b_hat):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X: (np.matrix of size N x (deg_true +1))\n",
    "    y: (np.array) of size deg_true + 1 x 1\n",
    "    b_hat: (np.array) of size N x (deg_true + 1)\n",
    "    Returns:\n",
    "    emp_risk: (float) \n",
    "    \"\"\"\n",
    "    # Get # of observations\n",
    "    N = X.shape[0]\n",
    "    # Calculate Predictions\n",
    "    y_hat = X @ b_hat\n",
    "    # Calculate squared errors and then empirical risk\n",
    "    sum_of_squared_errors = sum((y_hat-y)**2)\n",
    "    emp_risk = sum_of_squared_errors / N\n",
    "    emp_risk = emp_risk / 2  # because we have 1/2 in our loss function\n",
    "    return emp_risk\n",
    "\n",
    "\n",
    "def noisy_emp_and_gen_risk(d, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    d: (int) degree of polynomial desired\n",
    "    n: (int) number of samples to be generated in \n",
    "\n",
    "    Outputs:\n",
    "    training_error: (float) average sum of squares of loss function on training data\n",
    "    generalization_error: (float) average Sum of Squares of loss function on test data\n",
    "    \"\"\"\n",
    "    # Generate design matrices\n",
    "    X_train = get_design_mat(x_train, d)\n",
    "    X_test = get_design_mat(x_test, d)\n",
    "\n",
    "    # Calculate b_hat\n",
    "    b_hat = least_squares_estimator(X_train, y_train)\n",
    "    training_error = empirical_risk(X_train, y_train, b_hat)\n",
    "    generalization_error = empirical_risk(X_test, y_test, b_hat)\n",
    "\n",
    "    return training_error, generalization_error, b_hat\n",
    "\n",
    "\n",
    "def poly_risk_gen(d, n, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Ouptut:\n",
    "    train_error_arr: (np.array) e_t for various n\n",
    "    test_error_arr: (np.array) e_g for various n\n",
    "    \"\"\"\n",
    "    # Initiliaze np arrays\n",
    "    train_error_arr = []\n",
    "    test_error_arr = []\n",
    "\n",
    "    # Iterate over N\n",
    "    for i in range(d+1, len(n)):\n",
    "\n",
    "        # Get relevant subset of data\n",
    "        train_x_subset = x_train[:i+1]\n",
    "        train_y_subset = y_train[:i+1]\n",
    "\n",
    "        # Calculate e_t, e_g, and append to output\n",
    "        training_error, generalization_error, b_hat = noisy_emp_and_gen_risk(\n",
    "            d, train_x_subset, train_y_subset, x_test, y_test)\n",
    "        train_error_arr.append(training_error)\n",
    "        test_error_arr.append(generalization_error)\n",
    "\n",
    "    return train_error_arr, test_error_arr, b_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values at Index 0 For Vectors b_Hat and coef 1.2401199240321432 1.2401199240328558\n",
      "Difference rounded to 5 decimal places: -0.0\n",
      "Values at Index 1 For Vectors b_Hat and coef 4.660482295807032 4.660482295806109\n",
      "Difference rounded to 5 decimal places: 0.0\n",
      "Values at Index 2 For Vectors b_Hat and coef -3.60348096540093 -3.603480965401607\n",
      "Difference rounded to 5 decimal places: 0.0\n",
      "Values at Index 3 For Vectors b_Hat and coef 3.0169141328419995 3.016914132842649\n",
      "Difference rounded to 5 decimal places: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Set the degree of the polynomial\n",
    "d = 3\n",
    "\n",
    "# Return coefficients\n",
    "coef = get_d(d)\n",
    "\n",
    "# Generate training and test data -> N_train is the size of the train sample to draw, N_test for test\n",
    "N_train = 100\n",
    "N_test = 1000\n",
    "\n",
    "X_train, y_train = draw_sample(d, coef, N_train)\n",
    "X_test, y_test = draw_sample(d, coef, N_test)\n",
    "\n",
    "# Generate design matrices\n",
    "Xd_train = get_design_mat(X_train, d)\n",
    "Xd_test = get_design_mat(X_test, d)\n",
    "\n",
    "b_hat = least_squares_estimator(Xd_train, y_train)\n",
    "\n",
    "# Compare coef and b_hat values (should be same as we provide the data-generating distribution)\n",
    "for i in range(len(b_hat)):\n",
    "    print('Values at Index', i,\n",
    "          'For Vectors b_Hat and coef', coef[i], b_hat[i])\n",
    "    print(\"Difference rounded to 5 decimal places:\",\n",
    "          np.round(coef[i]-b_hat[i], 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Risk for Polynomial Degree 1 is: 0.004491582698944798\n",
      "Empirical Risk for Polynomial Degree 2 is: 0.0018319961209322514\n",
      "Empirical Risk for Polynomial Degree 3 is: 6.005538633243545e-26\n",
      "Empirical Risk for Polynomial Degree 4 is: 9.935065881852637e-25\n",
      "Empirical Risk for Polynomial Degree 5 is: 4.624649950054569e-21\n",
      "Empirical Risk for Polynomial Degree 6 is: 1.1032789503415328e-18\n"
     ]
    }
   ],
   "source": [
    "# Iterate through values 1-> 7, which will be\n",
    "# the degree of our polynomial used to predict y (lowest risk should be from coeff degree chosen)\n",
    "for i in range(1, 7):\n",
    "\n",
    "    # Get new design matrices for polynomial i\n",
    "    Xd_train = get_design_mat(X_train, i)\n",
    "    Xd_test = get_design_mat(X_test, i)\n",
    "\n",
    "    # Calculate best coefficient for each term\n",
    "    new_b_hat = least_squares_estimator(Xd_train, y_train)\n",
    "\n",
    "    # Calculate empirical risk for polynomial degree i\n",
    "    # Use the test set that we generated\n",
    "    current_risk = empirical_risk(Xd_test, y_test, new_b_hat)\n",
    "    print(\"Empirical Risk for Polynomial Degree\", i, \"is:\", current_risk)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7f43726a79b79bb18500e3546bed249e1c1aa16f3227c093295a5c944512c00"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
